 Deep learning is a field of machine learning utilizing massive neural networks, massive datasets, and accelerated computing on GPUs.
 
 PyTorch is an open-source Python framework from the Facebook AI Research team used for developing deep neural networks. 
 I like to think of PyTorch as an extension of Numpy that has some convenience classes for defining neural networks and accelerated computations using GPUs
 
 I have learned that all deep learning is regression line/curve fitting and optimizing. 
 
 Take for example a linear classification model with y = 2x1 + x2 - 18=0, as it's equation. 
 
 x1 = Test scores
 x2 = Grade score
 
 Based on these features alone, our model classifies into accepted(1) or rejected(0)
 
 yhat = the prediction
 yhat = 1 if y > 0 and 0 if y < 0
 
 
what is the score of the student who got 7 in the test and 6 for grades?

(y = 2*7 + 6 - 18) = 2

yhat = 1 if y > 0

therefore this student passed above the regression line.

clear? :) 

Perceptron.

Error Functions.

Gradient Descent.
- this is an adaptive method by which a function (line/curve) adjusts its orientation to minimize an error function.

QUIZ QUESTION
Which of the following conditions should be met in order to apply gradient descent? (Check all that apply.)
- differentiable and continuous.

Discrete vs Continuous predictions.

discrete = yes/no.
countinuous = probability.

Activation function: Step (discrete) vs Sigmoid (continuous) .

replaces a classification line with a series of lines (probability zones) based on maginitude of error function. 

QUIZ QUESTION
The sigmoid function is defined as sigmoid(x) = 1/(1+e-x). 
If the score is defined by 4x1 + 5x2 - 9 = score, 
then which of the following points has exactly a 50% probability of being blue or red? (Choose all that are correct.)
(1,1), (2,4), (5,-5), (-4,5)

MULTICLASS classification and Softmax (activation function).
all probablities add to one, for each possible class in the model. 

Quiz: Coding Softmax
And now, your time to shine! Let's code the formula for the Softmax function in Python.

import numpy as np

# Write a function that takes as input a list of numbers, and returns
# the list of values given by the softmax function.
def softmax(L):
    pass

One hot encoding. used to map labels to multi-attribute datasets. a form of data preprocessing for our models.

The model answers the question : 
 - which answer has the highest likelihood?
 - yhat = max_likelihood
 - in a softmax activation function.
 
 A softmax activation function will adjust the curve to optimize maximum likelihood. 
 Maximum likelihood. this is a function that measures the overall accuracy of the regression line's predictions in a sample. 
 
 Maximizing probabilities: Error function. 
 
 
 
 
 
 
 













